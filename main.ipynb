{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ephemeral/taremu/miniconda3/envs/ws/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import neptune\n",
    "import torch\n",
    "from neptune.utils import stringify_unsupported\n",
    "\n",
    "from src.attackers import get_attacker\n",
    "from src.config.meta_config import get_pydantic_models_from_path\n",
    "from src.evaluator import Evaluator\n",
    "from src.gradio import run_gradio\n",
    "from src.server import Server\n",
    "from src.utils import create_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of configs: 1\n"
     ]
    }
   ],
   "source": [
    "cfgs = get_pydantic_models_from_path(\"custom.yaml\")\n",
    "print(f\"Number of configs: {len(cfgs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WsConfig(meta=MetaConfig(device='cuda:7', use_neptune=False, neptune_project='ORG/PROJ', seed=123, out_root_dir='out_llama/', result_dir='results/default'), gradio=GradioConfig(skip=True, make_public=False, port=7860, default_prompt='Write a long essay about war.'), server=ServerConfig(model=ModelConfig(skip=False, name='google/gemma-2b-it', use_fp16=True, use_flashattn2=True, prompt_max_len=800, response_max_len=800, n_beams=1, use_sampling=True, sampling_temp=0.7), watermark=WatermarkConfig(scheme=<WatermarkScheme.KGW: 'kgw'>, generation=WatermarkGenerationConfig(seeding_scheme='selfhash', gamma=0.25, delta=4.0), detection=WatermarkDetectionConfig(normalizers=[], ignore_repeated_ngrams=True, z_threshold=4.0)), disable_watermark=False), attacker=AttackerConfig(algo=<AttackerAlgo.OUR: 'our'>, model=ModelConfig(skip=False, name='google/gemma-2b-it', use_fp16=True, use_flashattn2=True, prompt_max_len=800, response_max_len=800, n_beams=1, use_sampling=True, sampling_temp=0.7), querying=AttackerQueryingConfig(skip=False, dataset='c4', batch_size=64, start_from_batch_num=0, end_at_batch_num=500, apply_watermark=True), learning=AttackerLearningConfig(skip=False, mode=<AttackerLearningMode.FAST: 'fast'>, nb_queries=1), generation=AttackerGenerationConfig(spoofer_strength=10.0, w_abcd=2.0, w_partials=1.0, w_empty=0.5, w_future=0.0, min_wm_count_nonempty=2, min_wm_mass_empty=7e-05, future_num_cands=5, future_num_options_per_fillin=10, future_prefix_size=10, future_local_w_decay=0.9, panic_from=750, repetition_penalty=1.6, use_ft_counts=True, use_graceful_conclusion=True, sysprompt=<SyspromptType.STANDARD: 'standard'>, dipper_chunk=3, dipper_lexdiv=60, dipper_orderdiv=20, recursive_iters=1, prevent_eos_if_zest_bad=True, clip_at=2.0)), evaluator=EvaluatorConfig(skip=False, get_server_prompts_from=None, run_baseline_only=False, batch_size=4, metrics=[<EvalMetric.DETECTOR: 'detector'>, <EvalMetric.PPL: 'ppl'>, <EvalMetric.GPT4: 'gpt4'>, <EvalMetric.SELF: 'self'>], eval_class=<EvalClass.SPOOFING: 'spoofing'>, eval_mode=<EvalMode.TGT_C4: 'c4realnews-val-10'>, start_from_idx=-1))]\n"
     ]
    }
   ],
   "source": [
    "for cfg in cfgs:\n",
    "    print(cfgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7e27f77b5ab0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/ephemeral/taremu/miniconda3/envs/ws/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "for cfg in cfgs:\n",
    "    out_dir = cfg.get_result_path()\n",
    "    print(out_dir)\n",
    "    with create_open(f\"{out_dir}/config.txt\", \"w\") as f:\n",
    "        json.dump(cfg.model_dump(mode=\"json\"), indent=4, fp=f)\n",
    "    run = None\n",
    "    server = Server(cfg.meta, cfg.server)\n",
    "    # print(server.watermarks[0].spawn_logits_processor().hash_key)\n",
    "    # print(server.watermarks[0].spawn_logits_processor().rng)\n",
    "    attacker = get_attacker(cfg)\n",
    "    attacker.query_server_and_save(server)\n",
    "    attacker.load_queries_and_learn(base=False)\n",
    "    attacker.load_queries_and_learn(base=True)\n",
    "    evaluator = Evaluator(\n",
    "            cfg.meta.seed,\n",
    "            cfg.evaluator,\n",
    "            server,\n",
    "            verbose=True,\n",
    "            neptune_project=cfg.meta.neptune_project,\n",
    "            run=run,\n",
    "        )\n",
    "    evaluator.run_eval(server, attacker, out_dir=out_dir)\n",
    "    server = None  # type: ignore\n",
    "    attacker = None  # type: ignore\n",
    "    evaluator = None  # type: ignore\n",
    "    run = None\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
